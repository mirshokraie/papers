\chapter{Conclusion} \label{Chap:conc}
\javascript is increasingly being used to create modern interactive web applications that offload a considerable amount of their execution to the client-side. \javascript is a notoriously challenging language for web developers to use, maintain, analyze and test. This thesis has focused on exploring strategies for testing \javascript-based web applications. In accordance to the goal of this dissertation we designed two research questions:
\begin{itemize}
\item [RQ1] How can we generate effective test cases for \javascript web applications?
\item [RQ2] How can we effectively assess the quality of the written test suites for \javascript applications?
\end{itemize}
\section{Contributions}
%The main contributions of the thesis can be summarized as follows:
The main contributions of the thesis in response to the first research question (RQ1) are as follows: 
\begin{itemize}
\item A new automated technique for \javascript regression testing, which is based on dynamic analysis to infer invariant assertions; The obtained assertions are injected back into the \javascript code to uncover regression faults in subsequent revisions of the web application under test. 
\item An automatic technique to generate test cases for \javascript functions and events; We use a mutation-based algorithm to effectively generate test oracles, capable of detecting regression \javascript and DOM-level faults. The technique uses a combination of function converge maximization and function state abstraction algorithms to efficiently generate unit test cases.
\item Exploiting an existing DOM-based test suite to generate unit-level assertions for applications that highly interact with the DOM through the underlying \javascript code; We utilize
existing DOM-dependent assertions as well as useful execution information inferred from a DOM-based test suite to automatically generate assertions used for testing individual \javascript functions.
\end{itemize}
To address the second research question (RQ2), we made the following contribution:
\begin{itemize}
\item The first \javascript mutation testing tool, which is capable of guiding the mutation generation towards behaviour-affecting mutants in error-prone portions of the code; The mutation testing method combines dynamic and static analysis to mutate branches that are within highly ranked functions and exhibit high structural complexity.
\end{itemize}
\section{Threats to Validity}
In this section we discuss the threats to validity of our results.
An external threat to the validity of our results is the limited number 
of web applications we use to evaluate the usefulness of the proposed techniques.
Unfortunately, few real-world \javascript applications with up-to-date test suites and rich version history are publicly available. We mitigated this threat by (1) using web applications from various domains, code size, and functionality, as well as \selenium test cases, which are written by developers, and (2) mimicking regression faults through injecting mutations that represent common \javascript applications faults.

One challenge in conducting our experiments was the lack of existing \javascript tools to form a baseline for comparison, and as a result, one of the external threat to validity of evaluating \mutandis (\chapref{mutandis}) is that we do not perform a quantitative comparison 
of our technique with other mutation techniques.

Another threat concerns validating failed assertions through manual inspection during the evaluation of \jseft (\chapref{jseft}) and \atrina (\chapref{atrina}). This is a time intensive task, and thus could be error-prone. To mitigate this threat, we carefully examine the code in which the assertion failed to make sure that the injected fault was indeed responsible for the assertion failure.

A relatively low number of generated mutants to evaluate the effectiveness of \mutandis (\chapref{mutandis}) is also a threat to validity. 
In order to find equivalent mutants, the application's code should be manually inspected, and thus this threat is shared by other studies that attempt to detect equivalent mutants.
For example it took us more than 4 hours to distinguish the equivalent mutants for \jquery in our study. Since this is labour and time intensive task it can be error-prone and biased towards our judgment, though we made every effort to mitigate this threat by precisely examining the application's code. 





