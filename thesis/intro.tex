\chapter{Introduction} \label{chap:intro}
In this section, we provide an introduction to modern web application testing followed by some of the current techniques used for automating the testing process.
 
\section{Web Application Testing} \label{Sec:web-testing}
The importance of automated testing of web applications arises from the ever increasing
reliance on these systems in social and organizational
applications. Testing helps to improve the quality and dependability of these applications. However, writing high-quality test cases is time and effort intensive for developers.
Automatic test case generation can significantly reduce the time and manual effort, while
increasing the reliability of web applications.

\javascript is the common engine of modern web applications. 
Developers employ \javascript to add functionality, dynamically change the Document Object Model (DOM) structure,
and communicate with web servers. Given the increasing reliance of web applications on this language, it is important to check its correct behaviour.

Writing test suites that achieve high code coverage and high fault finding capability for \javascript applications is particularly challenging compared with traditional languages.
The event-driven and highly dynamic nature of \javascript, as well as its runtime interaction with the Document Object Model (DOM) make \javascript applications error-prone \cite{Ocariza:esem2013} and difficult to test.
The extensive interaction of \javascript with the DOM (and indirectly CSS) can result in many execution paths and states. The huge event space of such applications makes it challenging for the tester to cover the whole state space in a limited amount of time. Moreover, writing test oracles with high fault finding capability requires a tester to precisely analyze the interaction between the \javascript and the DOM. Mapping between the two component becomes difficult as the \javascript code and the DOM increase in size. 

To test \javascript-based web applications, developers
often write test cases using frameworks such as \selenium to examine the correct interaction of the user with web application (GUI testing) and \qunit to test the proper functionality of the individual units (unit testing).
Although such frameworks help to automate test execution, the
test cases need to be written manually, which can be tedious
and inefficient. 
Using \selenium framework to write DOM-based tests and assertions
requires little knowledge about the internal operations performed at the client side code. Rather, the tester needs only basic knowledge of common event sequences to cover important DOM elements to assert. 
This makes it easier for the tester to write DOM-based test suites. However, DOM-based assertions can potentially miss the related portion of
code-level failure, while more fine grained unit-level assertions are capable of detecting such faults. Furthermore, since DOM-based tests are agnostic of the \javascript code, finding the root cause of an error during DOM-based testing is more expensive than during unit testing. On the other hand,
writing unit test assertions for web applications that have rich interaction with the DOM through their \javascript code is more tedious. 
To write unit-level assertions, the tester needs to understand the full range of interaction between the code level operations of a unit and the DOM level operations of a system, and thus may fail to assert the correctness of a particular behaviour when the unit is used as a part of a system. The inherent characteristics of unit and DOM-based tests, indicate that they are complementary and that there is a trade-off in individually using each to detect faults. 

As far as test generation is concerned, Marchetto and Tonella \cite{marchetto:search} propose a search-based algorithm for generating event-based sequences to test Ajax applications. 
Mesbah et al.  \cite{mesbah:tweb11} apply dynamic analysis to construct a model of the application's state space, from which event-based test cases are automatically generated. In subsequent work \cite{mesbah:tse12}, they propose generic and application-specific invariants as a form of automated soft oracles for testing \ajax applications.
Sen \etal \cite{sen:fse13} recently proposed a record and replay framework called Jalangi. It incorporates selective record-replay as well as shadow values and shadow execution to enable writing of heavy-weight dynamic analyses.
The framework is able to track generic faults such as \code{null} and \code{undefined} values as well as type inconsistencies in \javascript. 
Jensen \etal \cite{jensen:fse13} propose a technique to test the correctness of communication patterns between client and server in \ajax applications by incorporating server interface descriptions.
They construct server interface descriptions through an inference technique that can learn communication patterns from sample data.
Saxena \etal \cite{song:symb10} combine random test generation with the use of symbolic execution for systematically exploring a \javascript application's event space as well as its value space, for security testing.

There has been limited work on oracle generation for testing. 
Fraser \etal \cite{fraser:tse12} propose $\mu$TE\-ST, which employs a mutant-based oracle generation technique.  It automatically generates unit tests for Java object-oriented classes by using a genetic algorithm to target mutations with high impact on the application's behaviour. They further identify~\cite{fraser:issta11} relevant pre-conditions on the test inputs and post-conditions on the outputs to ease human comprehension.
%\shabnam{differential test generation added for issta}
Differential test case generation approaches \cite{taneja:ase08, elbaum:tse09} are similar to mutation-based techniques in that they aim to generate test cases that show the difference between two versions of a program. However, mutation-based techniques such as ours, do not require two different versions of the application.
Rather, the generated differences are in the form of controllable mutations that can be used to generate test cases capable of detecting
regression faults in future versions of the program.
%\karthik{So what's the advantage of having the differences in the form of controllable mutations ?}
Staats \etal \cite{staats:icse11} address the problem of selecting oracle data,  which is formed as a subset of internal state variables as well as outputs for which the expected values are determined.
They apply mutation testing to produce oracles and rank the inferred oracles in terms of their fault finding capability. 

Artzi \etal propose \artemis \cite{artzi:icse11}, which supports automated testing of \javascript applications.
\artemis considers the event-driven execution model of a \javascript application for feedback-directed testing. 
Although, researchers have recently developed automated test generation techniques for \javascript-based applications \cite{artzi:icse11, marchetto:search, tonella:icst08, mesbah:tse12, song:symb10}, current techniques suffer from two main shortcomings, namely, they:
\begin{enumerate} 
%\vspace{-0.15in}
\item Target the generation of \emph{event sequences}, which operate at the event-level or DOM-level to cover the state space of the application. These techniques fail to capture faults that  do not propagate to an observable DOM state. As such, they potentially miss this portion of code-level \javascript faults. In order to capture such faults, effective test generation techniques need to target the code at the \javascript unit-level, in addition to the event-level.
\item Either ignore the oracle problem altogether or simplify it through generic \emph{soft oracles}, such as  W3C HTML  validation \cite{artzi:icse11,mesbah:tse12}, or  \javascript runtime exceptions \cite{artzi:icse11}.
A generated test case without assertions is not useful since coverage alone is not the goal of software testing. For such generated test cases, the tester still needs to  manually write many assertions, which is time and effort intensive. 
On the other hand, soft oracles  target generic fault types and are limited in their fault finding capabilities.   %\cite{Richardson:icse92}. 
%While there has been some work on the generation of test inputs \cite{song:symb10},  
%Despite such limitations, the automatic creation of strong test oracles, \ie assertions, has not gained much attention. 
However, to be practically useful, unit testing requires strong oracles  to determine whether the application under test executes correctly.
\end{enumerate}

\section{Adequacy Assessment} \label{Sec:adequacy}
While automated testing can help the tester to assure the application's dependability and detect faults in the application code, it does not reveal the trustworthiness of the written tests.
In order to understand how well the functionality and the data is being tested, we need to assess the quality of the tests.
A large body of research has been accomplished to assess the quality of test suites
from different perspectives: (1) code coverage, and (2) mutation analysis.
%\begin{description} [noitemsep, nolistsep]
%\item [Code coverage] which measures the degree to which the application's code is covered through a particular test suite.
%\item [Mutation analysis] which measures the effectiveness of a test suite in terms of its ability to detect injected faults.
%\end{description}
While code coverage tells how much of the source code is exercised by the test suite, it does not provide sufficient insight into the actual quality of the tests. Mutation testing has been proposed as a fault-based testing technique to assess and improve the quality of a test suite.

The main idea of mutation testing is to create mutants (i.e., modified versions of the program) and check if the test suite is effective at detecting the mutants. 
The technique first generates a set of mutants by applying a set of well-defined mutation operators on the original version of the system under test. 
These mutation operators typically represent subtle mistakes, such as typos, commonly made by programmers. A test suite's adequacy is then measured by its ability to detect (or `kill') the mutants, which is known as the adequacy score (or mutation score).

Despite being an effective test adequacy assessment method~\cite{andrews:icse05,jia:tse10}, mutation testing suffers from two main issues.  First, there is a high \emph{computational cost} in executing the test suite against a potentially large set of generated mutants. Second, there is a significant amount of effort  involved in distinguishing \emph{equivalent mutants}, which are syntactically different but semantically identical to the original program~\cite{budd:acta82}.  Equivalent mutants have no observable effect on the application's behaviour, and as a result, cannot be killed by test cases. Empirical studies indicate that about 45\% of all undetected mutants are equivalent~\cite{schuler:tvr12, madeyski:tse13}.   
Establishing mutant equivalence is an undecidable problem~\cite{budd:acta82}. 
According to a recent study~\cite{madeyski:tse13}, it takes on average 15 minutes to manually assess one single first-order mutant. While detecting equivalent mutants consumes considerable amount of time, there is still no fully automated technique that is capable of detecting all the equivalent mutants \cite{madeyski:tse13}.

A large body of research has been conducted to turn mutation testing into a practical approach.
To reduce the computational cost of  mutation testing, researchers have
proposed three main approaches to generate a smaller subset of all possible mutants: 
(1) \emph{mutant clustering} \cite{ji:seke09}, which is an approach that chooses a subset of
mutants using clustering algorithms; (2)  \emph{selective mutation} \cite{barbosa:stvr01, siami:icse08, zhang:icse10}, which is based on a  
careful selection of more effective mutation operators to generate less mutants; and 
 (3) \emph{higher order mutation} (HOM) testing \cite{jia:scam08}, which tries to find 
rare but valuable higher order mutants that denote subtle faults \cite{jia:tse10}.   

The problem of detecting equivalent mutants has been tackled by many researchers. The main goal of all equivalent mutant detection techniques is to help the tester identify the equivalent mutants after they are generated. We, on the other hand, aim at reducing the probability of generating equivalent mutants in the first place.
According to the taxonomy suggested by Madeyski \etal \cite{madeyski:tse13}, there are three main categories of approaches that address the problem of equivalent mutants: (1) detecting equivalent mutants, (2) avoiding equivalent mutant generation, and (3) suggesting equivalent mutants. As far as equivalent mutant detection techniques are concerned, 
the most effective approach is proposed by
Offutt and Pan \cite{offutt:tvr97, offutt:compass96}, which uses constraint
solving and path analysis. The results of their evaluation showed that the approach is able to detect on average the 45\% of the equivalent mutants. 
However, these solutions are involved with considerable amount of manual effort and are error-prone.

Among avoiding equivalent mutant generation techniques, Adamopoulos \etal \cite{adamopoulos:gecco04} present a co-evolutionary approach by designing a fitness function to detect and avoid possible equivalent mutants.
Dom\'inguez-Jim\'enez \etal \cite{dominguez:ist11} propose an evolutionary mutation testing
technique based on a genetic algorithm to cope with the high computational cost of mutation 
testing by reducing the number of mutants. Their system generates a strong subset
of mutants, which is composed of surviving and difficult to kill mutants. 
Their technique, however, cannot distinguish equivalent mutants from surviving non-equivalent mutants.
Langdon \etal have applied multi-object genetic programming to generate higher order mutants 
\cite{langdon:jss10}.
An important limitation of these approaches is that the generated
mutant needs to be executed against the test suite to compute its fitness function.
In contrast, our approach avoids  generating equivalent mutants in the first place,
thereby achieving greater efficiency.
Bottaci \cite{bottaci:icstw10} presents a mutation analysis technique based on the available type information at run-time to avoid generating incompetent mutants. 
This approach is applicable for dynamically typed programs such as \javascript. 
However, the efficiency of the technique is unclear as they do not provide any empirical evaluation of their approach.
Gligoric \etal \cite{gligoric:issta13} conduct the first study on performing selective mutation to avoid generating equivalent mutants in concurrent code. The results show that there are important differences between the concurrent mutation and sequential mutation operators. The authors show that sequential and concurrent mutation operators are independent, and thus they propose sets of operators that can be used for mutation testing of concurrent codes. 

Among the equivalent mutant suggestion techniques, Schuler \etal \cite{schuler:issta09} suggest possible equivalent mutants by checking invariant violations. They
generate multiple mutated versions and then classify the versions based on the number of violated invariants.
The system recommends testers to focus on those mutations that violate the most invariants.
In a follow-up paper \cite{schuler:tvr12}, they extend their work to assess the role of code coverage changes in detecting equivalent mutants. 
Kintis \etal \cite{kintis:icst12} present a technique called I-EQM to dynamically isolate first order equivalent mutants. They
further extend the coverage impact approach \cite{schuler:tvr12} to classify more killable mutants.  
In addition to coverage impact, the classification scheme utilizes second order mutation to assess first order mutants as killable. 
To generate mutants, they utilize Javalanche \cite{schuler:tvr12}.

Deng \etal \cite{deng:icst13} implement a version of statement deletion (SDL) mutation operator for Java within the muJava mutation system. The design of SDL operator is based on a theory that performing mutation testing using only one mutation operator can result in generating effective tests. However, the authors cannot conclude that SDL-based mutation is as effective as selective mutation, which contains a sufficient set of mutation operators from all possible operators. 

%Ayari \etal \cite{ayari:gecco07} and Fraser \etal \cite{fraser:tse12} apply search based techniques to automatically generate test cases using mutation testing for Java applications. Harman \etal \cite{harman:fse11} propose SHOM approach which combines dynamic symbolic execution and Search based software testing to generate strongly adequate test data to kill first and higher order mutants for C programs. However, all these approaches make use of mutation testing for the purpose of test case generation, and thus to generate mutants they rely on the available mutation testing frameworks.
%
%The problem of detecting equivalent mutants has been tackled by many researchers.
%Dom\'inguez-Jim\'enez \etal \cite{dominguez:ist11} propose an evolutionary mutation testing
%technique based on a genetic algorithm to cope with the high computational cost of mutation 
%testing by reducing the number of mutants. Their system generates a strong subset
%of mutants, which is composed of surviving and difficult to kill mutants. 
%Their technique, however, cannot distinguish equivalent mutants from surviving non-equivalent mutants, which are neither killed nor
%equivalent.
%Langdon \etal have applied multi-object genetic programming to generate higher order mutants 
%\cite{langdon:jss10}.
%An important limitation of these approaches is that the generated
%mutant needs to be executed against the test suite to compute its fitness function, and hence incur high performance overheads.
%Schuler \etal \cite{schuler:issta09} detect possible equivalent mutants by checking invariant violations. They
%generate multiple mutated versions and then classify the versions based on the number of violated invariants.
%The system recommends testers to focus on those mutations that violate the most invariants.
%In a follow-up paper \cite{schuler:icst10}, they extend their work to assess the role of code coverage changes in detecting equivalent mutants. 
%Bottaci \cite{bottaci:icstw10} presents a mutation analysis technique based on the available type information at run-time to avoid generating incompetent mutants. This approach is applicable for dynamically typed programs such as \javascript. However, the efficiency of the technique is unclear as they do not provide any empirical evaluation of their approach. 
%
\section{Research Questions} \label{Sec:researchq}
We designed two research questions in accordance to the ultimate goal of this thesis which is improving the dependability of \javascript web applications:

{\bf RQ 1.3.A.} \emph{How can we generate effective test cases for \javascript web applications?}

Systematic testing methods are required to verify the correct behaviour of web applications. The combination of technologies such as CSS, HTML, and \javascript makes testing of such applications a tedious task.
In response to web testing challenges, we (1) designed an automated test case and oracle generator, which is capable of detecting faults
in the \javascript applications for both unit and DOM level, and (2) propose an approach to exploit the existing DOM-based test suite in order to generate unit-level assertions. 

{\bf RQ 1.3.B.} \emph{How can we effectively assess the quality of the written test suites for \javascript applications?}

Various testing approaches are created to verify the correctness of an application. However the generated tests raise the question whether those tests sufficiently cover the requirements that have originated the application.  In response to this question, mutation testing is applied to expose weaknesses in the test suite.
In this proposal we propose a new \javascript mutation testing approach, which helps to guide the
mutation generation process towards parts of the code that are error-prone or likely to influence the program's
output.

\section{Contributions} \label{Sec:contrib}
We have conducted an
extensive study on different aspects of \javascript testing. In response to the first and second research questions as outlined in \secref{researchq}, the following papers have been published:
\begin{itemize}
\item JSART: JavaScript Assertion-based Regression Testing \cite{mirshokraie:icwe12}:
S. Mirshokraie and A. Mesbah, ICWE, 2012, 238-252;
\item Efficient JavaScript Mutation Testing \cite{mirshokraie:icst13}:
S. Mirshokraie, A. Mesbah and K. Pattabiraman, ICST, 2013, 74-83; (Best paper Runner-up award)
\item PYTHIA: Generating Test Cases with Oracles
for JavaScript Applications \cite{shabnam:ase13}: 
S. Mirshokraie, A. Mesbah and K. Pattabiraman, ASE, 2013, New Ideas Track, 610-615;
\item JSEFT: Automated JavaScript Unit Test Generation:
S. Mirshokraie, A. Mesbah and K. Pattabiraman, ICST, 2015;
\item Guided Mutation Testing for JavaScript Web Applications:
S. Mirshokraie, A. Mesbah and K. Pattabiraman, TSE, 2015;
\end{itemize}

I have also contributed to the following related publications:
\begin{itemize}
\item Automated Analysis of CSS Rules to Support Style Maintenance \cite{mesbah:icse12}: 
A. Mesbah and S. Mirshokraie, ICSE'12, 408-418;
\item A Systematic Mapping Study of Web Application Testing \cite{garousi:ist13}: 
V. Garousi, A. Mesbah, A. Betin Can and S. Mirshokraie, IST, vol. 55, no. 8, 1374-1396, 2013;
\end{itemize}
